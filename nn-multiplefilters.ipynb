{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":75676,"sourceType":"datasetVersion","datasetId":42780},{"sourceId":9294520,"sourceType":"datasetVersion","datasetId":5627188}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importing Necessary Libraries\nWe begin by importing the necessary libraries for handling image processing, model creation, and visualization. These include TensorFlow, OpenCV, NumPy, and others.","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, UpSampling2D, Add\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom skimage.metrics import structural_similarity as ssim\nimport matplotlib.pyplot as pl\nfrom sklearn.model_selection import train_test_split\n\n\n# Define paths and parameters\ndataset_path = '/kaggle/input/natural-images/natural_images/'\ntarget_size = (256, 256)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-01T12:44:28.478910Z","iopub.execute_input":"2024-09-01T12:44:28.480001Z","iopub.status.idle":"2024-09-01T12:44:29.189431Z","shell.execute_reply.started":"2024-09-01T12:44:28.479955Z","shell.execute_reply":"2024-09-01T12:44:29.188449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preparation\nLoading and Processing Images\nThe dataset consists of natural images that are resized to 256x256 pixels. We apply three different edge detection filters (Sobel, Laplacian, Prewitt) to each image.","metadata":{}},{"cell_type":"code","source":"# Utilize mixed precision training\nfrom tensorflow.keras.mixed_precision import set_global_policy\nset_global_policy('mixed_float16')\ncount =0\n# Function to apply Sobel filter\ndef apply_sobel_filter(image):\n    sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n    sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n    return cv2.magnitude(sobel_x, sobel_y)\n\n# Function to apply Laplacian filter\ndef apply_laplacian_filter(image):\n    return cv2.Laplacian(image, cv2.CV_64F)\n\n# Function to apply Prewitt filter\ndef apply_prewitt_filter(image):\n    kernelx = np.array([[1, 0, -1], [1, 0, -1], [1, 0, -1]], dtype=int)\n    kernely = np.array([[1, 1, 1], [0, 0, 0], [-1, -1, -1]], dtype=int)\n    return cv2.filter2D(image, cv2.CV_64F, kernelx) + cv2.filter2D(image, cv2.CV_64F, kernely)\n\n# Function to load and process images with all filters\ndef load_and_process_images_with_filters(dataset_path, target_size):\n    global count\n    original_images = []\n    sobel_images = []\n    laplacian_images = []\n    prewitt_images = []\n\n    for category in os.listdir(dataset_path):\n        category_path = os.path.join(dataset_path, category)\n        for image_name in os.listdir(category_path):\n            image_path = os.path.join(category_path, image_name)\n            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n            if count>=3000:\n                return (np.expand_dims(np.array(original_images), axis=-1) / 255.0, \n            np.expand_dims(np.array(sobel_images), axis=-1) / 255.0, \n            np.expand_dims(np.array(laplacian_images), axis=-1) / 255.0,\n            np.expand_dims(np.array(prewitt_images), axis=-1) / 255.0)\n            \n            if image is not None:\n                resized_image = cv2.resize(image, target_size)\n                original_images.append(resized_image)\n                sobel_images.append(apply_sobel_filter(resized_image))\n                laplacian_images.append(apply_laplacian_filter(resized_image))\n                prewitt_images.append(apply_prewitt_filter(resized_image))\n                count+=1\n                \n    return (np.expand_dims(np.array(original_images), axis=-1) / 255.0, \n            np.expand_dims(np.array(sobel_images), axis=-1) / 255.0, \n            np.expand_dims(np.array(laplacian_images), axis=-1) / 255.0,\n            np.expand_dims(np.array(prewitt_images), axis=-1) / 255.0)\n\n# Load images with filters\noriginal_images, sobel_images, laplacian_images, prewitt_images = load_and_process_images_with_filters(dataset_path, target_size)\n\n# Split the data into training, validation, and test sets\nX_train, X_temp, y_train_sobel, y_temp_sobel = train_test_split(original_images, sobel_images, test_size=0.3, random_state=42)\ny_train_laplacian, y_temp_laplacian = train_test_split(laplacian_images, test_size=0.3, random_state=42)\ny_train_prewitt, y_temp_prewitt = train_test_split(prewitt_images, test_size=0.3, random_state=42)\n\nX_val, X_test, y_val_sobel, y_test_sobel = train_test_split(X_temp, y_temp_sobel, test_size=0.5, random_state=42)\ny_val_laplacian, y_test_laplacian = train_test_split(y_temp_laplacian, test_size=0.5, random_state=42)\ny_val_prewitt, y_test_prewitt = train_test_split(y_temp_prewitt, test_size=0.5, random_state=42)\n\n# Verify the split\nprint(\"Training Set Shape:\", X_train.shape)\nprint(\"Validation Set Shape:\", X_val.shape)\nprint(\"Test Set Shape:\", X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T12:44:29.978580Z","iopub.execute_input":"2024-09-01T12:44:29.979643Z","iopub.status.idle":"2024-09-01T12:44:44.728062Z","shell.execute_reply.started":"2024-09-01T12:44:29.979600Z","shell.execute_reply":"2024-09-01T12:44:44.726984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Architecture\nWe define a convolutional neural network with a U-Net inspired architecture that includes residual connections. This architecture is utilized for each filter (Sobel, Laplacian, Prewitt).","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, UpSampling2D, Add\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nfrom skimage.metrics import structural_similarity as ssim\n\n# Use MirroredStrategy for multi-GPU training\nstrategy = tf.distribute.MirroredStrategy()\n\n# Model creation function (same as before, can be used for all filters)\ndef create_improved_filter_model(input_shape):\n    with strategy.scope():\n        inputs = Input(shape=input_shape)\n\n        # Downsample\n        conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n        conv1 = BatchNormalization()(conv1)\n        conv1 = MaxPooling2D((2, 2))(conv1)\n\n        conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv1)\n        conv2 = BatchNormalization()(conv2)\n        conv2 = MaxPooling2D((2, 2))(conv2)\n\n        conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv2)\n        conv3 = BatchNormalization()(conv3)\n\n        # Upsample\n        up1 = UpSampling2D((2, 2))(conv3)\n        up1 = Conv2D(128, (3, 3), activation='relu', padding='same')(up1)\n        up1 = BatchNormalization()(up1)\n\n        conv2_upsampled = UpSampling2D((2, 2))(conv2)  # Upsample conv2 to match the shape of up1\n        up1 = Add()([up1, conv2_upsampled])  # Residual connection\n\n        up2 = UpSampling2D((2, 2))(up1)\n        up2 = Conv2D(64, (3, 3), activation='relu', padding='same')(up2)\n        up2 = BatchNormalization()(up2)\n\n        conv1_upsampled = UpSampling2D((2, 2))(conv1)  # Upsample conv1 to match the shape of up2\n        up2 = Add()([up2, conv1_upsampled])  # Residual connection\n\n        # Output layer\n        outputs = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2)\n\n        model = Model(inputs, outputs)\n        model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n    \n    return model\n\ninput_shape = (256, 256, 1)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-01T12:44:59.911597Z","iopub.execute_input":"2024-09-01T12:44:59.912548Z","iopub.status.idle":"2024-09-01T12:44:59.928142Z","shell.execute_reply.started":"2024-09-01T12:44:59.912506Z","shell.execute_reply":"2024-09-01T12:44:59.927181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Training\nUsing TensorFlow's MirroredStrategy, we distribute the training across multiple GPUs for improved performance. The models for each filter are trained and validated over 15 epochs, with a learning rate scheduler and early stopping for optimization.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import LearningRateScheduler\n\ndef lr_scheduler(epoch, lr):\n    decay_rate = 0.1\n    decay_step = 5\n    if epoch % decay_step == 0 and epoch:\n        return lr * decay_rate\n    return lr\n\nlr_callback = LearningRateScheduler(lr_scheduler, verbose=1)\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\n\n\n# Train models for each filter\nmodels_dict = {}\n\nfor filter_name, y_train, y_val, y_test in [('Sobel', y_train_sobel, y_val_sobel, y_test_sobel), \n                                            ('Laplacian', y_train_laplacian, y_val_laplacian, y_test_laplacian), \n                                            ('Prewitt', y_train_prewitt, y_val_prewitt, y_test_prewitt)]:\n    model = create_improved_filter_model(input_shape)\n    history = model.fit(\n        X_train, y_train,\n        epochs=15,\n        validation_data=(X_val, y_val),\n        batch_size=16,\n        callbacks=[lr_callback, early_stopping]\n    )\n    models_dict[filter_name] = model\n\n    # Plot training results for each filter\n    plt.figure(figsize=(10, 5))\n    plt.plot(history.history['loss'], label='Training Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.title(f'Training and Validation Loss Over Epochs ({filter_name})')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n\n    # Evaluate the model on the test set\n    test_loss, test_mae = model.evaluate(X_test, y_test)\n    print(f\"{filter_name} - Test Loss: {test_loss}\")\n    print(f\"{filter_name} - Test MAE: {test_mae}\")\n\n    # Calculate SSIM for a sample image\n    index = 0\n    y_pred = model.predict(X_test)\n    ssim_value = ssim(y_test[index].squeeze(), y_pred[index].squeeze(), data_range=1.0)\n    print(f\"{filter_name} - SSIM Value: {ssim_value}\")\n\n# Save the models for further use\nfor filter_name, model in models_dict.items():\n    model.save(f'{filter_name}_filter_model.h5')","metadata":{"execution":{"iopub.status.busy":"2024-09-01T12:46:23.697225Z","iopub.execute_input":"2024-09-01T12:46:23.698057Z","iopub.status.idle":"2024-09-01T13:00:00.914221Z","shell.execute_reply.started":"2024-09-01T12:46:23.698012Z","shell.execute_reply":"2024-09-01T13:00:00.913361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualisation","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing import image\nfrom keras.models import Model\n\n# Define the function to get feature maps from a specific layer\ndef get_feature_maps(model, layer_name, input_image):\n    # Get the layer\n    layer = model.get_layer(name=layer_name)\n    \n    # Create a model that outputs the feature maps of the specified layer\n    feature_map_model = Model(inputs=model.input, outputs=layer.output)\n    \n    # Predict feature maps for the input image\n    feature_maps = feature_map_model.predict(input_image)\n    \n    return feature_maps\n\n# Define the function to plot feature maps\ndef plot_feature_maps(feature_maps, layer_name):\n    num_feature_maps = feature_maps.shape[-1]  # Number of feature maps\n    size = feature_maps.shape[1]  # Size of each feature map (assuming square)\n    \n    # Number of rows and columns in the grid\n    num_cols = 8\n    num_rows = (num_feature_maps // num_cols) + (num_feature_maps % num_cols != 0)\n    \n    plt.figure(figsize=(num_cols * 2, num_rows * 2))\n    \n    for i in range(num_feature_maps):\n        plt.subplot(num_rows, num_cols, i + 1)\n        plt.imshow(feature_maps[0, :, :, i], cmap='viridis')\n        plt.axis('off')\n    \n    plt.suptitle(f'Feature Maps of Layer: {layer_name}')\n    plt.show()\n\n# Example function call\ndef visualize_layer_features(model, layer_name, img_path):\n    # Load and preprocess an example image\n    img = image.load_img(img_path, target_size=(256, 256), color_mode='grayscale')\n    input_image = image.img_to_array(img)\n    input_image = np.expand_dims(input_image, axis=0)  # Add batch dimension\n\n    # Get feature maps for the specified layer\n    feature_maps = get_feature_maps(model, layer_name, input_image)\n    \n    # Plot the feature maps\n    plot_feature_maps(feature_maps, layer_name)\n\n# Example usage\n# Update with the layer names you are interested in\nlayer_names = ['conv2d_36', 'conv2d_37', 'conv2d_38', 'conv2d_39', 'conv2d_40', 'conv2d_41']\nimg_path = '/kaggle/input/testimg/testimg.jpg'  # Replace with the actual path to your image\n\nfor layer_name in layer_names:\n    visualize_layer_features(model, layer_name, img_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-01T13:25:03.636363Z","iopub.execute_input":"2024-09-01T13:25:03.637350Z","iopub.status.idle":"2024-09-01T13:25:33.559040Z","shell.execute_reply.started":"2024-09-01T13:25:03.637305Z","shell.execute_reply":"2024-09-01T13:25:33.557748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}